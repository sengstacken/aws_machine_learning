{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Comprehend - Custom Text Classification\n",
    "\n",
    "This lab is based off the blog post found [here](https://aws.amazon.com/blogs/machine-learning/building-a-custom-classifier-using-amazon-comprehend/).  This uses some data that has been pre-parsed and split in a public facing S3 bucket.  You will need to update this notebook with your own s3 output location and IAM user policy.\n",
    "\n",
    "Furthermore, we've reduced the number of documents to speed up the classification training time.\n",
    "\n",
    "Please email awsaaron@amazon.com for questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Typically you'll copy data from S3 into the Sagemaker notebook instance, however, in this example we are not really using the power of Sagemaker for custom model training but using the AI Service - Amazon Comprehend.  To use that, we'll need our data in S3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n",
      "sagemaker-us-east-1-626825435328\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "prefix = 'NLP.Classification'\n",
    "os.environ[\"AWS_REGION\"] = region\n",
    "region = boto3.Session().region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket_name = sagemaker.Session().default_bucket()\n",
    "\n",
    "print(region)\n",
    "print(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = 's3://aws-ml-blog/artifacts/comprehend-custom-classification/comprehend-train.csv'\n",
    "testing_data = 's3://aws-ml-blog/artifacts/comprehend-custom-classification/comprehend-test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the data from the public bucket to your local instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://aws-ml-blog/artifacts/comprehend-custom-classification/comprehend-train.csv to ./comprehend-train.csv\n",
      "download: s3://aws-ml-blog/artifacts/comprehend-custom-classification/comprehend-test.csv to ./comprehend-test.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp {training_data} .\n",
    "!aws s3 cp {testing_data} ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SCIENCE_AND_MATHEMATICS</td>\n",
       "      <td>What is an \\imaginary number\\\"? \\n What is an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTERTAINMENT_AND_MUSIC</td>\n",
       "      <td>What's the cheapest source for ordering DVDs f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BUSINESS_AND_FINANCE</td>\n",
       "      <td>If I lose lots of money in stock in one year&amp;#...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCIENCE_AND_MATHEMATICS</td>\n",
       "      <td>When can a common man fly to moon? \\n My realt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SOCIETY_AND_CULTURE</td>\n",
       "      <td>When do you use a semicolon instead of a colon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99986</th>\n",
       "      <td>POLITICS_AND_GOVERNMENT</td>\n",
       "      <td>I need help reporting a person who is working ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99987</th>\n",
       "      <td>ENTERTAINMENT_AND_MUSIC</td>\n",
       "      <td>What happened to the rebate for 'Friends' seas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99988</th>\n",
       "      <td>POLITICS_AND_GOVERNMENT</td>\n",
       "      <td>Are terrorists allowed to edit \\factual inform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99989</th>\n",
       "      <td>SPORTS</td>\n",
       "      <td>do u think that STEVE NASH deserves the MVP???...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99990</th>\n",
       "      <td>EDUCATION_AND_REFERENCE</td>\n",
       "      <td>Hi everybody i need a hindi translator in duba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99991 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         class  \\\n",
       "0      SCIENCE_AND_MATHEMATICS   \n",
       "1      ENTERTAINMENT_AND_MUSIC   \n",
       "2         BUSINESS_AND_FINANCE   \n",
       "3      SCIENCE_AND_MATHEMATICS   \n",
       "4          SOCIETY_AND_CULTURE   \n",
       "...                        ...   \n",
       "99986  POLITICS_AND_GOVERNMENT   \n",
       "99987  ENTERTAINMENT_AND_MUSIC   \n",
       "99988  POLITICS_AND_GOVERNMENT   \n",
       "99989                   SPORTS   \n",
       "99990  EDUCATION_AND_REFERENCE   \n",
       "\n",
       "                                                    text  \n",
       "0      What is an \\imaginary number\\\"? \\n What is an ...  \n",
       "1      What's the cheapest source for ordering DVDs f...  \n",
       "2      If I lose lots of money in stock in one year&#...  \n",
       "3      When can a common man fly to moon? \\n My realt...  \n",
       "4      When do you use a semicolon instead of a colon...  \n",
       "...                                                  ...  \n",
       "99986  I need help reporting a person who is working ...  \n",
       "99987  What happened to the rebate for 'Friends' seas...  \n",
       "99988  Are terrorists allowed to edit \\factual inform...  \n",
       "99989  do u think that STEVE NASH deserves the MVP???...  \n",
       "99990  Hi everybody i need a hindi translator in duba...  \n",
       "\n",
       "[99991 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(training_data,header=None,names=['class','text'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SCIENCE_AND_MATHEMATICS', 'ENTERTAINMENT_AND_MUSIC',\n",
       "       'BUSINESS_AND_FINANCE', 'SOCIETY_AND_CULTURE',\n",
       "       'EDUCATION_AND_REFERENCE', 'COMPUTERS_AND_INTERNET',\n",
       "       'POLITICS_AND_GOVERNMENT', 'HEALTH', 'SPORTS',\n",
       "       'FAMILY_AND_RELATIONSHIPS'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SPORTS                      10000\n",
       "HEALTH                      10000\n",
       "FAMILY_AND_RELATIONSHIPS    10000\n",
       "SOCIETY_AND_CULTURE          9999\n",
       "POLITICS_AND_GOVERNMENT      9999\n",
       "SCIENCE_AND_MATHEMATICS      9999\n",
       "EDUCATION_AND_REFERENCE      9999\n",
       "BUSINESS_AND_FINANCE         9999\n",
       "ENTERTAINMENT_AND_MUSIC      9998\n",
       "COMPUTERS_AND_INTERNET       9998\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the size of the dataset, let's downsample it for the purposes of this lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POLITICS_AND_GOVERNMENT     109\n",
       "HEALTH                      106\n",
       "FAMILY_AND_RELATIONSHIPS    106\n",
       "BUSINESS_AND_FINANCE        106\n",
       "EDUCATION_AND_REFERENCE     100\n",
       "ENTERTAINMENT_AND_MUSIC     100\n",
       "SOCIETY_AND_CULTURE          97\n",
       "SCIENCE_AND_MATHEMATICS      97\n",
       "COMPUTERS_AND_INTERNET       94\n",
       "SPORTS                       85\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the downsampled dataset to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "a['text'] = '\"' + a['text'] + '\"'\n",
    "a.to_csv('limited_dataset.csv',header=None,index=None,quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "limited_dataset_path = 's3://'+bucket_name+'/'+prefix+'/limited_dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./limited_dataset.csv to s3://sagemaker-us-east-1-626825435328/NLP.Classification/limited_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp limited_dataset.csv {limited_dataset_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Classifier\n",
    "Create a custom document classifier, supply the name, location of training data, access role ARN, language, and output S3 bucket location\n",
    "\n",
    "Make sure you've added the following policy to your assumed role:\n",
    "\n",
    "```\n",
    "\n",
    "{\n",
    "  \"Version\": \"2012-10-17\",\n",
    "  \"Statement\": [\n",
    "      {\n",
    "         \"Action\": [\n",
    "            \"iam:PassRole\"\n",
    "         ],\n",
    "         \"Effect\": \"Allow\",\n",
    "         \"Resource\": \"*\"\n",
    "      }\n",
    "   ]\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DocumentClassifierArn': 'arn:aws:comprehend:us-east-1:626825435328:document-classifier/test', 'ResponseMetadata': {'RequestId': 'e189d608-740d-4d5e-a3c0-8e700b2be7c5', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'e189d608-740d-4d5e-a3c0-8e700b2be7c5', 'content-type': 'application/x-amz-json-1.1', 'content-length': '94', 'date': 'Mon, 28 Sep 2020 21:41:27 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# Instantiate Boto3 SDK:\n",
    "client = boto3.client('comprehend', region_name='us-east-1')\n",
    "classifier_name = 'custom_classification_immersion_day'\n",
    "\n",
    "# Create a document classifier\n",
    "create_response = client.create_document_classifier(\n",
    "      DocumentClassifierName=classifier_name,\n",
    "      DataAccessRoleArn=role,\n",
    "      InputDataConfig={\n",
    "          'S3Uri': limited_dataset_path,\n",
    "      },\n",
    "      LanguageCode='en',\n",
    "  )\n",
    "\n",
    "print(create_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check the status of the custom classifier.  You can run the following cell's multiple times to check the status if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe response: \n",
      " {'DocumentClassifierProperties': {'DocumentClassifierArn': 'arn:aws:comprehend:us-east-1:626825435328:document-classifier/test', 'LanguageCode': 'en', 'Status': 'TRAINING', 'SubmitTime': datetime.datetime(2020, 9, 28, 21, 41, 27, 541000, tzinfo=tzlocal()), 'InputDataConfig': {'S3Uri': 's3://sagemaker-us-east-1-626825435328/NLP.Classification/limited_dataset.csv'}, 'OutputDataConfig': {}, 'DataAccessRoleArn': 'arn:aws:iam::626825435328:role/service-role/AmazonSageMaker-ExecutionRole-20200926T132738', 'Mode': 'MULTI_CLASS'}, 'ResponseMetadata': {'RequestId': '2dce2589-4b5d-44bd-814b-e60a7d533cc6', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '2dce2589-4b5d-44bd-814b-e60a7d533cc6', 'content-type': 'application/x-amz-json-1.1', 'content-length': '489', 'date': 'Mon, 28 Sep 2020 22:01:22 GMT'}, 'RetryAttempts': 0}}\n",
      "\n",
      "List response: \n",
      " {'DocumentClassifierPropertiesList': [{'DocumentClassifierArn': 'arn:aws:comprehend:us-east-1:626825435328:document-classifier/test', 'LanguageCode': 'en', 'Status': 'TRAINING', 'SubmitTime': datetime.datetime(2020, 9, 28, 21, 41, 27, 541000, tzinfo=tzlocal()), 'InputDataConfig': {'S3Uri': 's3://sagemaker-us-east-1-626825435328/NLP.Classification/limited_dataset.csv'}, 'OutputDataConfig': {}, 'DataAccessRoleArn': 'arn:aws:iam::626825435328:role/service-role/AmazonSageMaker-ExecutionRole-20200926T132738', 'Mode': 'MULTI_CLASS'}], 'ResponseMetadata': {'RequestId': '920f8438-40f5-40db-9f5a-5100ada2d51f', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '920f8438-40f5-40db-9f5a-5100ada2d51f', 'content-type': 'application/x-amz-json-1.1', 'content-length': '495', 'date': 'Mon, 28 Sep 2020 22:01:22 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "describe_response = client.describe_document_classifier(\n",
    "    DocumentClassifierArn=create_response['DocumentClassifierArn'])\n",
    "print(\"Describe response: \\n\",describe_response)\n",
    "print()\n",
    "\n",
    "# List all classifiers in account\n",
    "list_response = client.list_document_classifiers()\n",
    "print(\"List response: \\n\", list_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:comprehend:us-east-1:626825435328:document-classifier/test'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe_response['DocumentClassifierProperties']['DocumentClassifierArn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions!\n",
    "\n",
    "Once the custom classification model is trained, now you can use if for batch or real-time predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an end point for real time model prediction.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create end point\n",
    "response = client.create_endpoint(\n",
    "    EndpointName='my-custom-classification-endpoint2',\n",
    "    ModelArn=describe_response['DocumentClassifierProperties']['DocumentClassifierArn'],\n",
    "    DesiredInferenceUnits=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response['EndpointArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = 'After my most recent doctors appointment, I came down with the flu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real-time\n",
    "real_time_response = client.classify_document(\n",
    "    Text=txt,\n",
    "    EndpointArn=response['EndpointArn']\n",
    ")\n",
    "print(real_time_response['Classes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's try a batch async prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch\n",
    "start_response = client.start_document_classification_job(\n",
    "    InputDataConfig={\n",
    "        'S3Uri': testing_data,\n",
    "    },\n",
    "    OutputDataConfig={\n",
    "        'S3Uri': s3_output_bucket\n",
    "    },\n",
    "    DataAccessRoleArn=data_access_arn,\n",
    "    DocumentClassifierArn=describe_response['DocumentClassifierProperties']['DocumentClassifierArn']\n",
    ")\n",
    "\n",
    "print(\"Start response: %s\\n\", start_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the status of the job\n",
    "describe_response = client.describe_document_classification_job(JobId=start_response['JobId'])\n",
    "print(\"Describe response: %s\\n\", describe_response)\n",
    "\n",
    "# List all classification jobs in account\n",
    "list_response = client.list_document_classification_jobs()\n",
    "print(\"List response: %s\\n\", list_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
