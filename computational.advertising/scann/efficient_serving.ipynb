{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JlLTP1Y-WHg"
   },
   "source": [
    "##### Copyright 2020 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2022-09-28T11:08:29.648288Z",
     "iopub.status.busy": "2022-09-28T11:08:29.648018Z",
     "iopub.status.idle": "2022-09-28T11:08:29.651857Z",
     "shell.execute_reply": "2022-09-28T11:08:29.651341Z"
    },
    "id": "if-ujOZN-Par"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uq9kCbELjzgJ"
   },
   "source": [
    "# Efficient serving\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/recommenders/examples/efficient_serving\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/recommenders/blob/main/docs/examples/efficient_serving.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/recommenders/blob/main/docs/examples/efficient_serving.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/recommenders/docs/examples/efficient_serving.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlFcUNXT7hSF"
   },
   "source": [
    "[Retrieval models](https://www.tensorflow.org/recommenders/examples/basic_retrieval) are often built to surface a handful of top candidates out of millions or even hundreds of millions of candidates. To be able to react to the user's context and behaviour, they need to be able to do this on the fly, in a matter of milliseconds.\n",
    "\n",
    "Approximate nearest neighbour search (ANN) is the technology that makes this possible. In this tutorial, we'll show how to use ScaNN - a state of the art nearest neighbour retrieval package - to seamlessly scale TFRS retrieval to millions of items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_s_2UgUWA9u"
   },
   "source": [
    "## What is ScaNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSvmiDQPsGmb"
   },
   "source": [
    "ScaNN is a library from Google Research that performs dense vector similarity search at large scale. Given a database of candidate embeddings, ScaNN indexes these embeddings in a manner that allows them to be rapidly searched at inference time. ScaNN uses state of the art vector compression techniques and carefully implemented algorithms to achieve the best speed-accuracy tradeoff. It can greatly outperform brute force search while sacrificing little in terms of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTpnORU7WEPD"
   },
   "source": [
    "## Building a ScaNN-powered model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXEZ3lZnWIVh"
   },
   "source": [
    "To try out ScaNN in TFRS, we'll build a simple MovieLens retrieval model, just as we did in the [basic retrieval](https://www.tensorflow.org/recommenders/examples/basic_retrieval) tutorial. If you have followed that tutorial, this section will be familiar and can safely be skipped.\n",
    "\n",
    "To start, install TFRS and TensorFlow Datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:08:29.656726Z",
     "iopub.status.busy": "2022-09-28T11:08:29.656185Z",
     "iopub.status.idle": "2022-09-28T11:08:32.621436Z",
     "shell.execute_reply": "2022-09-28T11:08:32.620418Z"
    },
    "id": "mD2hiRviCxFE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-recommenders\n",
      "  Using cached tensorflow_recommenders-0.7.2-py3-none-any.whl (89 kB)\n",
      "Collecting absl-py>=0.1.6\n",
      "  Using cached absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "Collecting tensorflow>=2.9.0\n",
      "  Using cached tensorflow-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (20.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (59.3.0)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.14.0)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.50.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting protobuf<3.20,>=3.9.2\n",
      "  Using cached protobuf-3.19.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (4.3.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.21.6)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.27.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Using cached tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.0.1-py3-none-any.whl (5.4 kB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Using cached flatbuffers-22.9.24-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (1.11.2)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (2.10.0)\n",
      "Collecting keras<2.11,>=2.10.0\n",
      "  Using cached keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-14.0.6-py2.py3-none-manylinux2010_x86_64.whl (14.1 MB)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.9.0->tensorflow-recommenders) (0.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow>=2.9.0->tensorflow-recommenders) (0.34.2)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow>=2.9.0->tensorflow-recommenders) (2.28.1)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.13.0-py2.py3-none-any.whl (174 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->tensorflow>=2.9.0->tensorflow-recommenders) (2.4.6)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow>=2.9.0->tensorflow-recommenders) (4.9)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow>=2.9.0->tensorflow-recommenders) (4.12.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow>=2.9.0->tensorflow-recommenders) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow>=2.9.0->tensorflow-recommenders) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow>=2.9.0->tensorflow-recommenders) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow>=2.9.0->tensorflow-recommenders) (2022.6.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow>=2.9.0->tensorflow-recommenders) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow>=2.9.0->tensorflow-recommenders) (3.8.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow>=2.9.0->tensorflow-recommenders) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: tensorboard-plugin-wit, libclang, keras, flatbuffers, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1-modules, protobuf, opt-einsum, oauthlib, keras-preprocessing, grpcio, gast, cachetools, astunparse, absl-py, requests-oauthlib, markdown, google-auth, google-auth-oauthlib, tensorboard, tensorflow, tensorflow-recommenders\n",
      "  Attempting uninstall: werkzeug\n",
      "    Found existing installation: Werkzeug 1.0.0\n",
      "    Uninstalling Werkzeug-1.0.0:\n",
      "      Successfully uninstalled Werkzeug-1.0.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.1\n",
      "    Uninstalling protobuf-3.20.1:\n",
      "      Successfully uninstalled protobuf-3.20.1\n",
      "Successfully installed absl-py-1.3.0 astunparse-1.6.3 cachetools-5.2.0 flatbuffers-22.9.24 gast-0.4.0 google-auth-2.13.0 google-auth-oauthlib-0.4.6 grpcio-1.50.0 keras-2.10.0 keras-preprocessing-1.1.2 libclang-14.0.6 markdown-3.4.1 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-3.19.6 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.27.0 tensorflow-recommenders-0.7.2 termcolor-2.0.1 werkzeug-2.2.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting tensorflow-datasets\n",
      "  Using cached tensorflow_datasets-4.7.0-py3-none-any.whl (4.7 MB)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets) (2.28.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets) (4.42.1)\n",
      "Requirement already satisfied: toml in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets) (0.10.2)\n",
      "Collecting etils[epath]\n",
      "  Using cached etils-0.8.0-py3-none-any.whl (127 kB)\n",
      "Collecting promise\n",
      "  Using cached promise-2.3-py3-none-any.whl\n",
      "Collecting tensorflow-metadata\n",
      "  Using cached tensorflow_metadata-1.10.0-py3-none-any.whl (50 kB)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets) (2.0.1)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets) (0.3.5.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets) (1.14.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets) (4.3.0)\n",
      "Collecting importlib-resources\n",
      "  Using cached importlib_resources-5.10.0-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets) (1.21.6)\n",
      "Requirement already satisfied: protobuf>=3.12.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets) (3.19.6)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow-datasets) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow-datasets) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow-datasets) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow-datasets) (2022.6.15)\n",
      "Requirement already satisfied: zipp in /opt/conda/lib/python3.7/site-packages (from etils[epath]->tensorflow-datasets) (3.8.1)\n",
      "Collecting googleapis-common-protos<2,>=1.52.0\n",
      "  Using cached googleapis_common_protos-1.56.4-py2.py3-none-any.whl (211 kB)\n",
      "Installing collected packages: promise, importlib-resources, googleapis-common-protos, etils, tensorflow-metadata, tensorflow-datasets\n",
      "Successfully installed etils-0.8.0 googleapis-common-protos-1.56.4 importlib-resources-5.10.0 promise-2.3 tensorflow-datasets-4.7.0 tensorflow-metadata-1.10.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow-recommenders\n",
    "%pip install --upgrade tensorflow-datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oEbc-66nDJzc"
   },
   "source": [
    "We also need to install `scann`: it's an optional dependency of TFRS, and so needs to be installed separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:08:32.626148Z",
     "iopub.status.busy": "2022-09-28T11:08:32.625892Z",
     "iopub.status.idle": "2022-09-28T11:08:34.640526Z",
     "shell.execute_reply": "2022-09-28T11:08:34.639478Z"
    },
    "id": "daEivxsJDO0Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scann\n",
      "  Using cached scann-1.2.8-cp37-cp37m-manylinux_2_27_x86_64.whl (10.4 MB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from scann) (1.14.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from scann) (1.21.6)\n",
      "Requirement already satisfied: tensorflow~=2.10.0 in /opt/conda/lib/python3.7/site-packages (from scann) (2.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.10.0->scann) (14.0.6)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.10.0->scann) (2.0.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.10.0->scann) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.10.0->scann) (4.3.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.10.0->scann) (1.1.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.10.0->scann) (0.2.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.10.0->scann) (20.1)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.10.0->scann) (2.10.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.10.0->scann) (2.10.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.10.0->scann) (3.19.6)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.10.0->scann) (22.9.24)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.10.0->scann) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.10.0->scann) (3.3.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.10.0->scann) (2.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.10.0->scann) (1.11.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.10.0->scann) (59.3.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.10.0->scann) (1.50.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.10.0->scann) (1.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.10.0->scann) (0.27.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow~=2.10.0->scann) (2.10.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow~=2.10.0->scann) (0.34.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->scann) (2.13.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->scann) (2.2.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->scann) (2.28.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->scann) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->scann) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->scann) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->scann) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->tensorflow~=2.10.0->scann) (2.4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->scann) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->scann) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->scann) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->scann) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->scann) (4.12.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->scann) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->scann) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->scann) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->scann) (1.26.12)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->scann) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->scann) (3.8.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->scann) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->scann) (3.2.2)\n",
      "Installing collected packages: scann\n",
      "Successfully installed scann-1.2.8\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bDe054pgDQdp"
   },
   "source": [
    "Set up all the necessary imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:08:34.644871Z",
     "iopub.status.busy": "2022-09-28T11:08:34.644635Z",
     "iopub.status.idle": "2022-09-28T11:08:36.810915Z",
     "shell.execute_reply": "2022-09-28T11:08:36.810274Z"
    },
    "id": "6ekaJkcuHsiY"
   },
   "outputs": [],
   "source": [
    "from typing import Dict, Text\n",
    "\n",
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:08:36.815171Z",
     "iopub.status.busy": "2022-09-28T11:08:36.814557Z",
     "iopub.status.idle": "2022-09-28T11:08:36.843326Z",
     "shell.execute_reply": "2022-09-28T11:08:36.842749Z"
    },
    "id": "WdTPCz136mvc"
   },
   "outputs": [],
   "source": [
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfmRuUgJWlEQ"
   },
   "source": [
    "And load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:08:36.847079Z",
     "iopub.status.busy": "2022-09-28T11:08:36.846530Z",
     "iopub.status.idle": "2022-09-28T11:08:41.628984Z",
     "shell.execute_reply": "2022-09-28T11:08:41.628278Z"
    },
    "id": "k-VF30hJn5-3"
   },
   "outputs": [],
   "source": [
    "# Load the MovieLens 100K data.\n",
    "ratings = tfds.load(\n",
    "    \"movielens/100k-ratings\",\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "# Get the ratings data.\n",
    "ratings = (ratings\n",
    "           # Retain only the fields we need.\n",
    "           .map(lambda x: {\"user_id\": x[\"user_id\"], \"movie_title\": x[\"movie_title\"]})\n",
    "           # Cache for efficiency.\n",
    "           .cache(tempfile.NamedTemporaryFile().name)\n",
    ")\n",
    "\n",
    "# Get the movies data.\n",
    "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")\n",
    "movies = (movies\n",
    "          # Retain only the fields we need.\n",
    "          .map(lambda x: x[\"movie_title\"])\n",
    "          # Cache for efficiency.\n",
    "          .cache(tempfile.NamedTemporaryFile().name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SiVuNZ-lWv0R"
   },
   "source": [
    "Before we can build a model, we need to set up the user and movie vocabularies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:08:41.633219Z",
     "iopub.status.busy": "2022-09-28T11:08:41.632643Z",
     "iopub.status.idle": "2022-09-28T11:08:44.542507Z",
     "shell.execute_reply": "2022-09-28T11:08:44.541774Z"
    },
    "id": "jw-iQKBBajnz"
   },
   "outputs": [],
   "source": [
    "user_ids = ratings.map(lambda x: x[\"user_id\"])\n",
    "\n",
    "unique_movie_titles = np.unique(np.concatenate(list(movies.batch(1000))))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids.batch(1000))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRbZCvWHWzPU"
   },
   "source": [
    "We'll also set up the training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:08:44.546472Z",
     "iopub.status.busy": "2022-09-28T11:08:44.545871Z",
     "iopub.status.idle": "2022-09-28T11:08:44.563006Z",
     "shell.execute_reply": "2022-09-28T11:08:44.562410Z"
    },
    "id": "FqV8p7N8CrEg"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ok3-kzr1bI7U"
   },
   "source": [
    "### Model definition\n",
    "\n",
    "Just as in the [basic retrieval](https://www.tensorflow.org/recommenders/examples/basic_retrieval) tutorial, we build a simple two-tower model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:08:44.566341Z",
     "iopub.status.busy": "2022-09-28T11:08:44.565834Z",
     "iopub.status.idle": "2022-09-28T11:08:44.572695Z",
     "shell.execute_reply": "2022-09-28T11:08:44.572145Z"
    },
    "id": "yX_j4pEVbKIS"
   },
   "outputs": [],
   "source": [
    "class MovielensModel(tfrs.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        embedding_dimension = 32\n",
    "\n",
    "        # Set up a model for representing movies.\n",
    "        self.movie_model = tf.keras.Sequential([\n",
    "          tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_movie_titles, mask_token=None),\n",
    "          # We add an additional embedding to account for unknown tokens.\n",
    "          tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Set up a model for representing users.\n",
    "        self.user_model = tf.keras.Sequential([\n",
    "          tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_user_ids, mask_token=None),\n",
    "            # We add an additional embedding to account for unknown tokens.\n",
    "          tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Set up a task to optimize the model and compute metrics.\n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "          metrics=tfrs.metrics.FactorizedTopK(\n",
    "            candidates=(\n",
    "                movies\n",
    "                .batch(128)\n",
    "                .cache()\n",
    "                .map(lambda title: (title, self.movie_model(title)))\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        # We pick out the user features and pass them into the user model.\n",
    "        user_embeddings = self.user_model(features[\"user_id\"])\n",
    "        # And pick out the movie features and pass them into the movie model,\n",
    "        # getting embeddings back.\n",
    "        positive_movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
    "\n",
    "        # The task computes the loss and the metrics.\n",
    "\n",
    "        return self.task(\n",
    "            user_embeddings,\n",
    "            positive_movie_embeddings,\n",
    "            candidate_ids=features[\"movie_title\"],\n",
    "            compute_metrics=not training\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JtO3lKR_XKkw"
   },
   "source": [
    "### Fitting and evaluation\n",
    "\n",
    "A TFRS model is just a Keras model. We can compile it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:08:44.575729Z",
     "iopub.status.busy": "2022-09-28T11:08:44.575242Z",
     "iopub.status.idle": "2022-09-28T11:08:44.678325Z",
     "shell.execute_reply": "2022-09-28T11:08:44.677690Z"
    },
    "id": "uOGTdwAAbuB6"
   },
   "outputs": [],
   "source": [
    "model = MovielensModel()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rGLyo-XXPmX"
   },
   "source": [
    "Estimate it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:08:44.682093Z",
     "iopub.status.busy": "2022-09-28T11:08:44.681630Z",
     "iopub.status.idle": "2022-09-28T11:08:48.784188Z",
     "shell.execute_reply": "2022-09-28T11:08:48.783439Z"
    },
    "id": "uf_E4dIMcGnk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10/10 [==============================] - 13s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 69806.4815 - regularization_loss: 0.0000e+00 - total_loss: 69806.4815\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 12s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 67485.7443 - regularization_loss: 0.0000e+00 - total_loss: 67485.7443\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 12s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 66316.6385 - regularization_loss: 0.0000e+00 - total_loss: 66316.6385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fde85e13b90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train.batch(8192), epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7xymbWgVXSrT"
   },
   "source": [
    "And evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:08:48.788329Z",
     "iopub.status.busy": "2022-09-28T11:08:48.787704Z",
     "iopub.status.idle": "2022-09-28T11:08:55.065618Z",
     "shell.execute_reply": "2022-09-28T11:08:55.064916Z"
    },
    "id": "EMlIj741cIT8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 15s 4s/step - factorized_top_k/top_1_categorical_accuracy: 0.0017 - factorized_top_k/top_5_categorical_accuracy: 0.0100 - factorized_top_k/top_10_categorical_accuracy: 0.0218 - factorized_top_k/top_50_categorical_accuracy: 0.1242 - factorized_top_k/top_100_categorical_accuracy: 0.2332 - loss: 49469.1289 - regularization_loss: 0.0000e+00 - total_loss: 49469.1289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.0017000000225380063,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.010049999691545963,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.021800000220537186,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.1242000013589859,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.23319999873638153,\n",
       " 'loss': 28260.953125,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 28260.953125}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test.batch(8192), return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RbHiBWqsFmf"
   },
   "source": [
    "## Approximate prediction\n",
    "\n",
    "The most straightforward way of retrieving top candidates in response to a query is to do it via brute force: compute user-movie scores for all possible movies, sort them, and pick a couple of top recommendations.\n",
    "\n",
    "In TFRS, this is accomplished via the `BruteForce` layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:08:55.069498Z",
     "iopub.status.busy": "2022-09-28T11:08:55.068911Z",
     "iopub.status.idle": "2022-09-28T11:08:55.153101Z",
     "shell.execute_reply": "2022-09-28T11:08:55.152266Z"
    },
    "id": "x_L2yAPjpHsk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x7fde8f08ac50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brute_force = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "brute_force.index_from_dataset(\n",
    "    movies.batch(128).map(lambda title: (title, model.movie_model(title)))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CzoNR28vXw7o"
   },
   "source": [
    "Once created and populated with candidates (via the `index` method), we can call it to get predictions out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow_recommenders.layers.factorized_top_k.BruteForce object at 0x7fde8f08ac50>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow_recommenders.layers.factorized_top_k.BruteForce object at 0x7fde8f08ac50>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as query_with_exclusions while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./poc_data/tempBF/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./poc_data/tempBF/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(\n",
    "    brute_force,\n",
    "    './poc_data/tempBF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = tf.saved_model.load('./poc_data/tempBF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_UserObject' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-51c14dddf39f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloaded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"42\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: '_UserObject' object is not callable"
     ]
    }
   ],
   "source": [
    "loaded([\"42\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:08:55.156923Z",
     "iopub.status.busy": "2022-09-28T11:08:55.156357Z",
     "iopub.status.idle": "2022-09-28T11:08:55.173697Z",
     "shell.execute_reply": "2022-09-28T11:08:55.173077Z"
    },
    "id": "SBo1Nu0Grife"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommendations: [b'Rudy (1993)' b\"Kid in King Arthur's Court, A (1995)\"\n",
      " b'Homeward Bound: The Incredible Journey (1993)']\n"
     ]
    }
   ],
   "source": [
    "# Get predictions for user 42.\n",
    "_, titles = brute_force(np.array([\"42\"]), k=3)\n",
    "\n",
    "print(f\"Top recommendations: {titles[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzNECPifr6i6"
   },
   "source": [
    "On a small dataset of under 1000 movies, this is very fast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:08:55.177087Z",
     "iopub.status.busy": "2022-09-28T11:08:55.176633Z",
     "iopub.status.idle": "2022-09-28T11:09:08.959164Z",
     "shell.execute_reply": "2022-09-28T11:09:08.958522Z"
    },
    "id": "w57iyu7Ir87Q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.78 ms ± 701 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _, titles = brute_force(np.array([\"42\"]), k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.ScaNN at 0x7fde85821cd0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scann = tfrs.layers.factorized_top_k.ScaNN(model.user_model, num_reordering_candidates=1000)\n",
    "scann.index_from_dataset(\n",
    "    movies.batch(128).map(lambda title: (title, model.movie_model(title)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommendations: [b\"Kid in King Arthur's Court, A (1995)\"\n",
      " b'Homeward Bound: The Incredible Journey (1993)' b'Cool Runnings (1993)'\n",
      " b'Angels in the Outfield (1994)' b'Bridges of Madison County, The (1995)'\n",
      " b'Aristocats, The (1970)' b'Winnie the Pooh and the Blustery Day (1968)'\n",
      " b'Lion King, The (1994)' b'Jungle Book, The (1994)'\n",
      " b'D3: The Mighty Ducks (1996)']\n"
     ]
    }
   ],
   "source": [
    "_, titles = scann(np.array([\"42\"]), k=10)\n",
    "print(f\"Top recommendations: {titles[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8 ms ± 116 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _, titles = scann(np.array([\"42\"]), k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://joseprsm.medium.com/how-to-recommend-anything-12b35a7561aa\n",
    "# docker run -p 8501:8501 --mount type=bind,source=/home/ec2-user/SageMaker/scann/savedscann,target=/models/index -e MODEL_NAME=index -t google/tf-serving-scann\n",
    "# curl -d '{\"instances\": [\"42\"]}' -X POST http://localhost:8501/v1/models/index:predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_with_exclusions while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./poc_data/savedscann/1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./poc_data/savedscann/1/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(\n",
    "            scann,\n",
    "            './poc_data/savedscann/1',\n",
    "            options=tf.saved_model.SaveOptions(namespace_whitelist=[\"Scann\"])\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2AjJsdrsClR"
   },
   "source": [
    "But what happens if we have more candidates - millions instead of thousands?\n",
    "\n",
    "We can simulate this by indexing all of our movies multiple times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:09:08.963169Z",
     "iopub.status.busy": "2022-09-28T11:09:08.962645Z",
     "iopub.status.idle": "2022-09-28T11:09:09.031126Z",
     "shell.execute_reply": "2022-09-28T11:09:09.030465Z"
    },
    "id": "AapJk84csTqV"
   },
   "outputs": [],
   "source": [
    "# Construct a dataset of movies that's 1,000 times larger. We \n",
    "# do this by adding several million dummy movie titles to the dataset.\n",
    "lots_of_movies = tf.data.Dataset.concatenate(\n",
    "    movies.batch(4096),\n",
    "    movies.batch(4096).repeat(1_000).map(lambda x: tf.zeros_like(x))\n",
    ")\n",
    "\n",
    "# We also add lots of dummy embeddings by randomly perturbing\n",
    "# the estimated embeddings for real movies.\n",
    "lots_of_movies_embeddings = tf.data.Dataset.concatenate(\n",
    "    movies.batch(4096).map(model.movie_model),\n",
    "    movies.batch(4096).repeat(1_000)\n",
    "      .map(lambda x: model.movie_model(x))\n",
    "      .map(lambda x: x * tf.random.uniform(tf.shape(x)))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viCLP9qSYBQh"
   },
   "source": [
    "We can build a `BruteForce` index on this larger dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:09:09.034848Z",
     "iopub.status.busy": "2022-09-28T11:09:09.034602Z",
     "iopub.status.idle": "2022-09-28T11:09:15.702625Z",
     "shell.execute_reply": "2022-09-28T11:09:15.701936Z"
    },
    "id": "mfY62oQbYA3Z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x7f7ab7a0eed0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brute_force_lots = tfrs.layers.factorized_top_k.BruteForce()\n",
    "brute_force_lots.index_from_dataset(\n",
    "    tf.data.Dataset.zip((lots_of_movies, lots_of_movies_embeddings))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OrkMt8O_xm-s"
   },
   "source": [
    "The recommendations are still the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
       "array([[ 0.11498411, -0.543408  ,  0.12411596, -0.04369251, -0.20710406,\n",
       "        -0.81840605, -0.00397614, -0.0717119 , -0.3115183 ,  0.17810631,\n",
       "         0.337274  , -0.43292025, -0.09064745, -0.2953079 , -0.14917158,\n",
       "         0.26707256,  0.30795622, -0.22303149, -0.16206278, -0.5529132 ,\n",
       "         0.14704572,  0.07343937,  0.08569661,  0.20068882, -0.02039822,\n",
       "         0.38444695, -0.2104183 ,  0.5670137 , -0.22032006,  0.03593822,\n",
       "        -0.21277799,  0.09496906]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.user_model(np.array([\"42\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:09:15.706421Z",
     "iopub.status.busy": "2022-09-28T11:09:15.706160Z",
     "iopub.status.idle": "2022-09-28T11:09:15.717013Z",
     "shell.execute_reply": "2022-09-28T11:09:15.716425Z"
    },
    "id": "I9fIYUeYxjki"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommendations: [b'Rudy (1993)' b'Powder (1995)' b\"Kid in King Arthur's Court, A (1995)\"]\n"
     ]
    }
   ],
   "source": [
    "_, titles = brute_force_lots(model.user_model(np.array([\"42\"])), k=3)\n",
    "\n",
    "print(f\"Top recommendations: {titles[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwF25ZzdseX8"
   },
   "source": [
    "But they take much longer. With a candidate set of 1 million movies, brute force prediction becomes quite slow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:09:15.720486Z",
     "iopub.status.busy": "2022-09-28T11:09:15.719985Z",
     "iopub.status.idle": "2022-09-28T11:09:18.976814Z",
     "shell.execute_reply": "2022-09-28T11:09:18.976082Z"
    },
    "id": "oetK_wNxsdw0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.8 ms ± 724 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _, titles = brute_force_lots(model.user_model(np.array([\"42\"])), k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mKF9yEeotbXQ"
   },
   "source": [
    "As the number of candidate grows, the amount of time needed grows linearly: with 10 million candidates, serving top candidates would take 250 milliseconds. This is clearly too slow for a live service.\n",
    "\n",
    "This is where approximate mechanisms come in.\n",
    "\n",
    "Using ScaNN in TFRS is accomplished via the `tfrs.layers.factorized_top_k.ScaNN` layer. It follow the same interface as the other top k layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:09:18.980766Z",
     "iopub.status.busy": "2022-09-28T11:09:18.980143Z",
     "iopub.status.idle": "2022-09-28T11:09:29.253016Z",
     "shell.execute_reply": "2022-09-28T11:09:29.252323Z"
    },
    "id": "SLgPmA90sbDL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.ScaNN at 0x7f7aad812d10>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scann = tfrs.layers.factorized_top_k.ScaNN(\n",
    "    num_reordering_candidates=500,\n",
    "    num_leaves_to_search=30\n",
    ")\n",
    "scann.index_from_dataset(\n",
    "    tf.data.Dataset.zip((lots_of_movies, lots_of_movies_embeddings))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scann import scann_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'scann.scann_ops.py.scann_ops' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-78d58c84a94a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscann_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'scann.scann_ops.py.scann_ops' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "scann_ops.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRI-qv7S2h97"
   },
   "source": [
    "The recommendations are (approximately!) the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:09:29.256888Z",
     "iopub.status.busy": "2022-09-28T11:09:29.256635Z",
     "iopub.status.idle": "2022-09-28T11:09:29.848858Z",
     "shell.execute_reply": "2022-09-28T11:09:29.848177Z"
    },
    "id": "HCkRn1VnxuXn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommendations: [b'Rudy (1993)' b'Powder (1995)' b\"Kid in King Arthur's Court, A (1995)\"]\n"
     ]
    }
   ],
   "source": [
    "_, titles = scann(model.user_model(np.array([\"42\"])), k=3)\n",
    "\n",
    "print(f\"Top recommendations: {titles[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iW1oBtcC2mb1"
   },
   "source": [
    "But they are much, much faster to compute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:09:29.852335Z",
     "iopub.status.busy": "2022-09-28T11:09:29.852094Z",
     "iopub.status.idle": "2022-09-28T11:09:31.481398Z",
     "shell.execute_reply": "2022-09-28T11:09:31.480722Z"
    },
    "id": "ooJsLhpWstlf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.35 ms ± 41.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _, titles = scann(model.user_model(np.array([\"42\"])), k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOYk0zi12q-0"
   },
   "source": [
    "In this case, we can retrieve the top 3 movies out of a set of ~1 million in around 2 milliseconds: 15 times faster than by computing the best candidates via brute force. The advantage of approximate methods grows even larger for larger datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tE7eL7ZzDKtl"
   },
   "source": [
    "## Evaluating the approximation\n",
    "\n",
    "When using approximate top K retrieval mechanisms (such as ScaNN), speed of retrieval often comes at the expense of accuracy. To understand this trade-off, it's important to measure the model's evaluation metrics when using ScaNN, and to compare them with the baseline.\n",
    "\n",
    "Fortunately, TFRS makes this easy. We simply override the metrics on the retrieval task with metrics using ScaNN, re-compile the model, and run evaluation.\n",
    "\n",
    "To make the comparison, let's first run baseline results. We still need to override our metrics to make sure they are using the enlarged candidate set rather than the original set of movies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:09:31.485580Z",
     "iopub.status.busy": "2022-09-28T11:09:31.484994Z",
     "iopub.status.idle": "2022-09-28T11:12:59.373279Z",
     "shell.execute_reply": "2022-09-28T11:12:59.372519Z"
    },
    "id": "ZZtJRQqBep_5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26min 30s, sys: 2min 4s, total: 28min 34s\n",
      "Wall time: 15min 52s\n"
     ]
    }
   ],
   "source": [
    "# Override the existing streaming candidate source.\n",
    "model.task.factorized_metrics = tfrs.metrics.FactorizedTopK(\n",
    "    candidates=tf.data.Dataset.zip((lots_of_movies, lots_of_movies_embeddings))\n",
    ")\n",
    "# Need to recompile the model for the changes to take effect.\n",
    "model.compile()\n",
    "\n",
    "%time baseline_result = model.evaluate(test.batch(8192), return_dict=True, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHFzcS5cQtB_"
   },
   "source": [
    "We can do the same using ScaNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:12:59.377276Z",
     "iopub.status.busy": "2022-09-28T11:12:59.376724Z",
     "iopub.status.idle": "2022-09-28T11:13:01.239328Z",
     "shell.execute_reply": "2022-09-28T11:13:01.238634Z"
    },
    "id": "5T-YxOqoKMje"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.9 s, sys: 1.38 s, total: 19.3 s\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "model.task.factorized_metrics = tfrs.metrics.FactorizedTopK(\n",
    "    candidates=scann\n",
    ")\n",
    "model.compile()\n",
    "\n",
    "# We can use a much bigger batch size here because ScaNN evaluation\n",
    "# is more memory efficient.\n",
    "%time scann_result = model.evaluate(test.batch(8192), return_dict=True, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0gnjcUUZ6-v"
   },
   "source": [
    "ScaNN based evaluation is much, much quicker. This advantage is going to grow even larger for bigger datasets, and so for large datasets it may be prudent to always run ScaNN-based evaluation to improve model development velocity.\n",
    "\n",
    "But how about the results? Fortunately, in this case the results are almost the same:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:13:01.243531Z",
     "iopub.status.busy": "2022-09-28T11:13:01.242879Z",
     "iopub.status.idle": "2022-09-28T11:13:01.246833Z",
     "shell.execute_reply": "2022-09-28T11:13:01.246178Z"
    },
    "id": "gcXUbZx3Fq4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brute force top-100 accuracy: 0.16\n",
      "ScaNN top-100 accuracy:       0.14\n"
     ]
    }
   ],
   "source": [
    "print(f\"Brute force top-100 accuracy: {baseline_result['factorized_top_k/top_100_categorical_accuracy']:.2f}\")\n",
    "print(f\"ScaNN top-100 accuracy:       {scann_result['factorized_top_k/top_100_categorical_accuracy']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2UJR-5nZ6YT"
   },
   "source": [
    "This suggests that on this artificial datase,  there is little loss from the approximation. In general, all approximate methods exhibit speed-accuracy tradeoffs. To understand this in more depth you can check out Erik Bernhardsson's [ANN benchmarks](https://github.com/erikbern/ann-benchmarks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-jdPPOlV3JOr"
   },
   "source": [
    "## Deploying the approximate model\n",
    "\n",
    "The `ScaNN`-based model is fully integrated into TensorFlow models, and serving it is as easy as serving any other TensorFlow model.\n",
    "\n",
    "We can save it as a `SavedModel` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:13:01.250617Z",
     "iopub.status.busy": "2022-09-28T11:13:01.250092Z",
     "iopub.status.idle": "2022-09-28T11:13:01.254232Z",
     "shell.execute_reply": "2022-09-28T11:13:01.253707Z"
    },
    "id": "eKxXVfJBLbiW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcatenateDataset element_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lots_of_movies_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:13:01.257328Z",
     "iopub.status.busy": "2022-09-28T11:13:01.256870Z",
     "iopub.status.idle": "2022-09-28T11:13:13.316067Z",
     "shell.execute_reply": "2022-09-28T11:13:13.315350Z"
    },
    "id": "KnVI_6N53WU5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_with_exclusions while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpnuqyc88e/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpnuqyc88e/model/assets\n"
     ]
    }
   ],
   "source": [
    "# We re-index the ScaNN layer to include the user embeddings in the same model.\n",
    "# This way we can give the saved model raw features and get valid predictions\n",
    "# back.\n",
    "scann = tfrs.layers.factorized_top_k.ScaNN(model.user_model, num_reordering_candidates=1000)\n",
    "scann.index_from_dataset(\n",
    "    tf.data.Dataset.zip((lots_of_movies, lots_of_movies_embeddings))\n",
    ")\n",
    "\n",
    "# Need to call it to set the shapes.\n",
    "_ = scann(np.array([\"42\"]))\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmp:\n",
    "    path = os.path.join(tmp, \"model\")\n",
    "    tf.saved_model.save(\n",
    "          scann,\n",
    "          path,\n",
    "          options=tf.saved_model.SaveOptions(namespace_whitelist=[\"Scann\"])\n",
    "    )\n",
    "\n",
    "    loaded = tf.saved_model.load(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O5vDZjro4lXG"
   },
   "source": [
    "and then load it and serve, getting exactly the same results back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:13:13.320268Z",
     "iopub.status.busy": "2022-09-28T11:13:13.319974Z",
     "iopub.status.idle": "2022-09-28T11:13:14.026888Z",
     "shell.execute_reply": "2022-09-28T11:13:14.026056Z"
    },
    "id": "TXm8smCt3iFB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommendations: [b'Rudy (1993)' b'Powder (1995)' b\"Kid in King Arthur's Court, A (1995)\"]\n"
     ]
    }
   ],
   "source": [
    "_, titles = loaded(tf.constant([\"42\"]))\n",
    "\n",
    "print(f\"Top recommendations: {titles[0][:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0Doal2ETqU4"
   },
   "source": [
    "The resulting model can be served in any Python service that has TensorFlow and ScaNN installed.\n",
    "\n",
    "It can also be served using a customized version of TensorFlow Serving, available as a Docker container on [Docker Hub](https://hub.docker.com/r/google/tf-serving-scann). You can also build the image yourself from the [Dockerfile](https://github.com/google-research/google-research/tree/master/scann/tf_serving)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gQsvn5PYbR-"
   },
   "source": [
    "## Tuning ScaNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "918uqacB7sNH"
   },
   "source": [
    "Now let's look into tuning our ScaNN layer to get a better performance/accuracy tradeoff. In order to do this effectively, we first need to measure our baseline performance and accuracy.\n",
    "\n",
    "From above, we already have a measurement of our model's latency for processing a single (non-batched) query (although note that a fair amount of this latency is from non-ScaNN components of the model).\n",
    "\n",
    "Now we need to investigate ScaNN's accuracy, which we measure through recall. A recall@k of x% means that if we use brute force to retrieve the true top k neighbors, and compare those results to using ScaNN to also retrieve the top k neighbors, x% of ScaNN's results are in the true brute force results. Let's compute the recall for the current ScaNN searcher.\n",
    "\n",
    "First, we need to generate the brute force, ground truth top-k:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:13:14.030845Z",
     "iopub.status.busy": "2022-09-28T11:13:14.030609Z",
     "iopub.status.idle": "2022-09-28T11:13:15.939422Z",
     "shell.execute_reply": "2022-09-28T11:13:15.938692Z"
    },
    "id": "qgf_QuP-8EXb"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-58369736b324>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# may lead to out-of-memory errors, because processing a batch of q queries against\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# a size-n dataset takes O(nq) space with brute force.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m titles_ground_truth = tf.concat([\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mbrute_force_lots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mqueries\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"user_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# Process queries in groups of 1000; processing them all at once with brute force\n",
    "# may lead to out-of-memory errors, because processing a batch of q queries against\n",
    "# a size-n dataset takes O(nq) space with brute force.\n",
    "titles_ground_truth = tf.concat([\n",
    "    brute_force_lots(queries, k=10)[1] for queries in\n",
    "    test.batch(1000).map(lambda x: model.user_model(x[\"user_id\"]))\n",
    "], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSZkWESc856P"
   },
   "source": [
    "Our variable `titles_ground_truth` now contains the top-10 movie recommendations returned by brute-force retrieval. Now we can compute the same recommendations when using ScaNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:13:15.943950Z",
     "iopub.status.busy": "2022-09-28T11:13:15.943260Z",
     "iopub.status.idle": "2022-09-28T11:13:17.008341Z",
     "shell.execute_reply": "2022-09-28T11:13:17.007380Z"
    },
    "id": "yUKtdf1X87mP"
   },
   "outputs": [],
   "source": [
    "# Get all user_id's as a 1d tensor of strings\n",
    "test_flat = np.concatenate(list(test.map(lambda x: x[\"user_id\"]).batch(1000).as_numpy_iterator()), axis=0)\n",
    "\n",
    "# ScaNN is much more memory efficient and has no problem processing the whole\n",
    "# batch of 20000 queries at once.\n",
    "_, titles = scann(test_flat, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTsTDiAZ9F6h"
   },
   "source": [
    "Next, we define our function that computes recall. For each query, it counts how many results are in the intersection of the brute force and the ScaNN results and divides this by the number of brute force results. The average of this quantity over all queries is our recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:13:17.012640Z",
     "iopub.status.busy": "2022-09-28T11:13:17.012145Z",
     "iopub.status.idle": "2022-09-28T11:13:17.016429Z",
     "shell.execute_reply": "2022-09-28T11:13:17.015687Z"
    },
    "id": "PCtBew2C9Gv0"
   },
   "outputs": [],
   "source": [
    "def compute_recall(ground_truth, approx_results):\n",
    "  return np.mean([\n",
    "      len(np.intersect1d(truth, approx)) / len(truth)\n",
    "      for truth, approx in zip(ground_truth, approx_results)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_tdxlKua9JR2"
   },
   "source": [
    "This gives us baseline recall@10 with the current ScaNN config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:13:17.019925Z",
     "iopub.status.busy": "2022-09-28T11:13:17.019291Z",
     "iopub.status.idle": "2022-09-28T11:13:30.876526Z",
     "shell.execute_reply": "2022-09-28T11:13:30.875840Z"
    },
    "id": "nMi4VtJD9K9P"
   },
   "outputs": [],
   "source": [
    "print(f\"Recall: {compute_recall(titles_ground_truth, titles):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gKpgkNseYWW8"
   },
   "source": [
    "We can also measure the baseline latency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:13:30.880352Z",
     "iopub.status.busy": "2022-09-28T11:13:30.879839Z",
     "iopub.status.idle": "2022-09-28T11:15:48.562465Z",
     "shell.execute_reply": "2022-09-28T11:15:48.561578Z"
    },
    "id": "81mO-GS4VJLJ"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scann' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fdf96edd9ed6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-n 1000 scann(np.array([\"42\"]), k=10)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2416\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2418\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2419\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</opt/conda/lib/python3.7/site-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m         \u001b[0mall_runs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m         \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m         \u001b[0mworst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/timeit.py\u001b[0m in \u001b[0;36mrepeat\u001b[0;34m(self, repeat, number)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scann' is not defined"
     ]
    }
   ],
   "source": [
    "%timeit -n 1000 scann(np.array([\"42\"]), k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UICnYQln9PAq"
   },
   "source": [
    "Let's see if we can do better!\n",
    "\n",
    "To do this, we need a model of how ScaNN's tuning knobs affect performance. Our current model uses ScaNN's tree-AH algorithm. This algorithm partitions the database of embeddings (the \"tree\") and then scores the most promising of these partitions using AH, which is a highly optimized approximate distance computation routine.\n",
    "\n",
    "The default parameters for TensorFlow Recommenders' ScaNN Keras layer sets `num_leaves=100` and `num_leaves_to_search=10`. This means our database is partitioned into 100 disjoint subsets, and the 10 most promising of these partitions is scored with AH. This means 10/100=10% of the dataset is being searched with AH.\n",
    "\n",
    "If we have, say, `num_leaves=1000` and `num_leaves_to_search=100`, we would also be searching 10% of the database with AH. However, in comparison to the previous setting, the 10% we would search will contain higher-quality candidates, because a higher `num_leaves` allows us to make finer-grained decisions about what parts of the dataset are worth searching.\n",
    "\n",
    "It's no surprise then that with `num_leaves=1000` and `num_leaves_to_search=100` we get significantly higher recall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:15:48.566199Z",
     "iopub.status.busy": "2022-09-28T11:15:48.565924Z",
     "iopub.status.idle": "2022-09-28T11:16:14.764050Z",
     "shell.execute_reply": "2022-09-28T11:16:14.763356Z"
    },
    "id": "vq6L1Qtl9Qan"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.975\n"
     ]
    }
   ],
   "source": [
    "scann2 = tfrs.layers.factorized_top_k.ScaNN(\n",
    "    model.user_model, \n",
    "    num_leaves=1000,\n",
    "    num_leaves_to_search=100,\n",
    "    num_reordering_candidates=1000)\n",
    "scann2.index_from_dataset(\n",
    "    tf.data.Dataset.zip((lots_of_movies, lots_of_movies_embeddings))\n",
    ")\n",
    "\n",
    "_, titles2 = scann2(test_flat, k=10)\n",
    "\n",
    "print(f\"Recall: {compute_recall(titles_ground_truth, titles2):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2WR8zPH9TtW"
   },
   "source": [
    "However, as a tradeoff, our latency has also increased. This is because the partitioning step has gotten more expensive; `scann` picks the top 10 of 100 partitions while `scann2` picks the top 100 of 1000 partitions. The latter can be more expensive because it involves looking at 10 times as many partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:16:14.767885Z",
     "iopub.status.busy": "2022-09-28T11:16:14.767381Z",
     "iopub.status.idle": "2022-09-28T11:18:32.306938Z",
     "shell.execute_reply": "2022-09-28T11:18:32.306241Z"
    },
    "id": "Po0kb4Mf9VhX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.6 ms ± 62.9 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1000 scann2(np.array([\"42\"]), k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCDzY0sc9Zgc"
   },
   "source": [
    "In general, tuning ScaNN search is about picking the right tradeoffs. Each individual parameter change generally won't make search both faster and more accurate; our goal is to tune the parameters to optimally trade off between these two conflicting goals.\n",
    "\n",
    "In our case, `scann2` significantly improved recall over `scann` at some cost in latency. Can we dial back some other knobs to cut down on latency, while preserving most of our recall advantage?\n",
    "\n",
    "Let's try searching 70/1000=7% of the dataset with AH, and only rescoring the final 400 candidates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:18:32.310674Z",
     "iopub.status.busy": "2022-09-28T11:18:32.310431Z",
     "iopub.status.idle": "2022-09-28T11:18:57.933379Z",
     "shell.execute_reply": "2022-09-28T11:18:57.932613Z"
    },
    "id": "jBp8Yvdj9pMQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.971\n"
     ]
    }
   ],
   "source": [
    "scann3 = tfrs.layers.factorized_top_k.ScaNN(\n",
    "    model.user_model,\n",
    "    num_leaves=1000,\n",
    "    num_leaves_to_search=70,\n",
    "    num_reordering_candidates=400)\n",
    "scann3.index_from_dataset(\n",
    "    tf.data.Dataset.zip((lots_of_movies, lots_of_movies_embeddings))\n",
    ")\n",
    "\n",
    "_, titles3 = scann3(test_flat, k=10)\n",
    "print(f\"Recall: {compute_recall(titles_ground_truth, titles3):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Isgpm7b9rgE"
   },
   "source": [
    "`scann3` delivers about a 3% absolute recall gain over `scann` while also delivering lower latency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T11:18:57.937141Z",
     "iopub.status.busy": "2022-09-28T11:18:57.936880Z",
     "iopub.status.idle": "2022-09-28T11:21:14.800316Z",
     "shell.execute_reply": "2022-09-28T11:21:14.799610Z"
    },
    "id": "JiDEWwtr9sKG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.6 ms ± 26.7 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1000 scann3(np.array([\"42\"]), k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NwWKyQgt9uh1"
   },
   "source": [
    "These knobs can be further adjusted to optimize for different points along the accuracy-performance pareto frontier. ScaNN's algorithms can achieve state-of-the-art performance over a wide range of recall targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UvlCsKyFU40k"
   },
   "source": [
    "## Further reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ikGqmNa9yRG"
   },
   "source": [
    "ScaNN uses advanced vector quantization techniques and highly optimized implementation to achieve its results. The field of vector quantization has a rich history with a variety of approaches. ScaNN's current quantization technique is detailed in [this paper](https://arxiv.org/abs/1908.10396), published at ICML 2020. The paper was also released along with [this blog article](https://ai.googleblog.com/2020/07/announcing-scann-efficient-vector.html) which gives a high level overview of our technique.\n",
    "\n",
    "Many related quantization techniques are mentioned in the references of our ICML 2020 paper, and other ScaNN-related research is listed at http://sanjivk.com/."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "efficient_serving.ipynb",
   "toc_visible": true
  },
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
